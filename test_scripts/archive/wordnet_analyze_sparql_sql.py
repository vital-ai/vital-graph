#!/usr/bin/env python3
"""
Analyze the SQL generated by SPARQL queries to understand why indexes aren't being used.
"""

import os
import time
from rdflib import Graph, URIRef
from sqlalchemy import URL, create_engine, text
from vitalgraph.store.store import VitalGraphSQLStore

# Database configuration
PG_HOST = os.getenv("PG_HOST", "127.0.0.1")
PG_PORT = os.getenv("PG_PORT", "5432")
PG_DATABASE = os.getenv("PG_DATABASE", "vitalgraphdb")
PG_USER = os.getenv("PG_USER", "postgres")
PG_PASSWORD = os.getenv("PG_PASSWORD", "")
GRAPH_NAME = "wordnet"

def analyze_sparql_query(g, query_name, sparql_query):
    """Analyze a SPARQL query by intercepting the SQL it generates."""
    print(f"\n{'='*60}")
    print(f"ANALYZING: {query_name}")
    print(f"{'='*60}")
    
    # Enable SQL logging to see what's generated
    import logging
    logging.basicConfig(level=logging.DEBUG)
    logger = logging.getLogger('sqlalchemy.engine')
    logger.setLevel(logging.INFO)
    
    print(f"\nSPARQL Query:")
    print(sparql_query)
    
    print(f"\nExecuting SPARQL query...")
    start_time = time.time()
    
    try:
        results = g.query(sparql_query)
        count = 0
        for row in results:
            count += 1
            if count >= 5:  # Stop after 5 results to avoid long execution
                break
        
        elapsed = time.time() - start_time
        print(f"Results: {count} found in {elapsed:.3f} seconds")
        
        if elapsed > 10:
            print("⚠ SLOW QUERY - This needs optimization!")
        elif elapsed > 5:
            print("⚠ MODERATE - Could be faster")
        else:
            print("✓ FAST - Good performance")
            
    except Exception as e:
        elapsed = time.time() - start_time
        print(f"ERROR after {elapsed:.3f} seconds: {e}")

def test_simple_alternatives(engine, interned_id):
    """Test simpler SQL alternatives that should use indexes."""
    print(f"\n{'='*60}")
    print("TESTING SIMPLE SQL ALTERNATIVES")
    print(f"{'='*60}")
    
    literal_table = f"{interned_id}_literal_statements"
    asserted_table = f"{interned_id}_asserted_statements"
    
    with engine.connect() as connection:
        
        # Test 1: Simple ILIKE on literal table
        print(f"\n1. Simple ILIKE on {literal_table}:")
        start_time = time.time()
        
        result = connection.execute(text(f"""
            EXPLAIN (ANALYZE, BUFFERS) 
            SELECT subject, object FROM {literal_table} 
            WHERE object ILIKE '%happy%' 
            LIMIT 10
        """))
        
        elapsed = time.time() - start_time
        print(f"Execution time: {elapsed:.3f} seconds")
        
        for row in result:
            line = row[0]
            if 'Index Scan' in line or 'Bitmap' in line:
                print(f"✓ {line}")
            elif 'Seq Scan' in line:
                print(f"✗ {line}")
            else:
                print(f"  {line}")
        
        # Test 2: Join between tables (similar to SPARQL)
        print(f"\n2. Join between asserted and literal tables:")
        start_time = time.time()
        
        result = connection.execute(text(f"""
            EXPLAIN (ANALYZE, BUFFERS) 
            SELECT a.subject, l.object 
            FROM {asserted_table} a
            JOIN {literal_table} l ON a.subject = l.subject
            WHERE l.object ILIKE '%happy%'
            LIMIT 10
        """))
        
        elapsed = time.time() - start_time
        print(f"Execution time: {elapsed:.3f} seconds")
        
        for row in result:
            line = row[0]
            if 'Index Scan' in line or 'Bitmap' in line:
                print(f"✓ {line}")
            elif 'Seq Scan' in line:
                print(f"✗ {line}")
            else:
                print(f"  {line}")

def main():
    # Build database URL
    db_url = URL.create(
        drivername="postgresql+psycopg",
        username=PG_USER,
        password=PG_PASSWORD or None,
        host=PG_HOST,
        port=PG_PORT,
        database=PG_DATABASE,
    )

    store = VitalGraphSQLStore()
    graph_iri = URIRef(f"http://vital.ai/graph/{GRAPH_NAME}")
    g = Graph(store=store, identifier=graph_iri)
    g.open(db_url)
    
    print("Connected to WordNet graph")
    print(f"Total triples: {len(g):,}")
    
    # Test the problematic SPARQL query
    sparql_query = """
PREFIX vital-core: <http://vital.ai/ontology/vital-core#>
PREFIX haley-ai-kg: <http://vital.ai/ontology/haley-ai-kg#>

SELECT ?entity ?entityName WHERE {
  ?entity a haley-ai-kg:KGEntity .
  ?entity vital-core:hasName ?entityName .
  FILTER(CONTAINS(LCASE(STR(?entityName)), "happy"))
}
LIMIT 5
"""
    
    analyze_sparql_query(g, "CONTAINS 'happy' in names", sparql_query)
    
    # Test simpler alternatives
    engine = create_engine(db_url)
    interned_id = store._interned_id
    test_simple_alternatives(engine, interned_id)
    
    print(f"\n{'='*60}")
    print("ANALYSIS COMPLETE")
    print(f"{'='*60}")
    print("\nKey findings:")
    print("- Check if SPARQL queries are using indexes (look for 'Bitmap Index Scan')")
    print("- Compare with simple SQL alternatives")
    print("- If SPARQL generates complex SQL without index usage, we need different approach")

if __name__ == "__main__":
    main()
